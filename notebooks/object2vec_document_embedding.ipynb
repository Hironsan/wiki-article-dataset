{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Embedding with Amazon SageMaker Object2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Introduction](#Introduction)\n",
    "2. [Background](#Background)\n",
    "  1. [Embedding documents using Object2Vec](#Embedding-documents-using-Object2Vec)\n",
    "3. [Download and preprocess Wikipedia data](#Download-and-preprocess-Wikipedia-data)\n",
    "  1. [Install and load dependencies](#Install-and-load-dependencies)\n",
    "  2. [Build vocabulary and tokenize datasets](#Build-vocabulary-and-tokenize-datasets)\n",
    "  3. [Upload preprocessed data to S3](#Upload-preprocessed-data-to-S3)\n",
    "4. [Define SageMaker session, Object2Vec image, S3 input and output paths](#Define-SageMaker-session,-Object2Vec-image,-S3-input-and-output-paths)\n",
    "5. [Train and deploy doc2vec](#Train-and-deploy-doc2vec)\n",
    "  1. [Learning performance boost with new features](#Learning-performance-boost-with-new-features)\n",
    "  2. [Training speedup with sparse gradient update](#Training-speedup-with-sparse-gradient-update)\n",
    "6. [Apply learned embeddings to document retrieval task](#Apply-learned-embeddings-to-document-retrieval-task)\n",
    "  1. [Comparison with the StarSpace algorithm](#Comparison-with-the-StarSpace-algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we introduce four new features to Object2Vec, a general-purpose neural embedding algorithm: negative sampling, sparse gradient update, weight-sharing, and comparator operator customization. The new features together broaden the applicability of Object2Vec, improve its training speed and accuracy, and provide users with greater flexibility. See [Introduction to the Amazon SageMaker Object2Vec](https://aws.amazon.com/blogs/machine-learning/introduction-to-amazon-sagemaker-object2vec/) if you aren’t already familiar with Object2Vec.\n",
    "\n",
    "We demonstrate how these new features extend the applicability of Object2Vec to a new Document Embedding use-case: A customer has a large collection of documents. Instead of storing these documents in its raw format or as sparse bag-of-words vectors, to achieve training efficiency in the various downstream tasks, she would like to instead embed all documents in a common low-dimensional space, so that the semantic distance between these documents are preserved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Object2Vec is a highly customizable multi-purpose algorithm that can learn embeddings of pairs of objects. The embeddings are learned such that it preserves their pairwise similarities in the original space.\n",
    "\n",
    "- Similarity is user-defined: users need to provide the algorithm with pairs of objects that they define as similar (1) or dissimilar (0); alternatively, the users can define similarity in a continuous sense (provide a real-valued similarity score).\n",
    "\n",
    "- The learned embeddings can be used to efficiently compute nearest neighbors of objects, as well as to visualize natural clusters of related objects in the embedding space. In addition, the embeddings can also be used as features of the corresponding objects in downstream supervised tasks such as classification or regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding documents using Object2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We demonstrate how, with the new features, Object2Vec can be used to embed a large collection of documents into vectors in the same latent space.\n",
    "\n",
    "Similar to the widely used Word2Vec algorithm for word embedding, a natural approach to document embedding is to preprocess documents as (sentence, context) pairs, where the sentence and its matching context come from the same document. The matching context is the entire document with the given sentence removed. The idea is to embed both sentence and context into a low dimensional space such that their mutual similarity is maximized, since they belong to the same document and therefore should be semantically related. The learned encoder for the context can then be used to encode new documents into the same embedding space. In order to train the encoders for sentences and documents, we also need negative (sentence, context) pairs so that the model can learn to discriminate between semantically similar and dissimilar pairs. It is easy to generate such negatives by pairing sentences with documents that they do not belong to. Since there are many more negative pairs than positives in naturally occurring data, we typically resort to random sampling techniques to achieve a balance between positive and negative pairs in the training data. The figure below shows pictorially how the positive pairs and negative pairs are generated from unlabeled data for the purpose of learning embeddings for documents (and sentences)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We show how Object2Vec with the new *negative sampling feature* can be applied to the document embedding use-case. In addition, we show how the other new features, namely, *weight-sharing*, *customization of comparator operator*, and *sparse gradient update*, together enhance the algorithm's performance and user-experience in and beyond this use-case. Sections [Learning performance boost with new features](#Learning-performance-boost-with-new-features) and [Training speedup with sparse gradient update](#Training-speedup-with-sparse-gradient-update) in this notebook provide a detailed introduction to the new features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and preprocess Wikipedia data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please be aware of the following requirements about the acknowledgment, copyright and availability, cited from the [data source description page](https://github.com/facebookresearch/StarSpace/blob/master/LICENSE.md).\n",
    "\n",
    "> Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "DATANAME=\"wikipedia\"\n",
    "DATADIR=\"/tmp/wiki\"\n",
    "\n",
    "mkdir -p \"${DATADIR}\"\n",
    "\n",
    "if [ ! -f \"${DATADIR}/${DATANAME}_train250k.txt\" ]\n",
    "then\n",
    "    echo \"Downloading wikipedia data\"\n",
    "    wget --quiet -c \"https://s3-ap-northeast-1.amazonaws.com/dev.tech-sketch.jp/chakki/public/ja.wikipedia_250k.zip\" -O \"${DATADIR}/${DATANAME}_train.zip\"\n",
    "    unzip \"${DATADIR}/${DATANAME}_train.zip\" -d \"${DATADIR}\"\n",
    "fi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '/tmp/wiki'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /tmp/wiki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install and load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "from itertools import chain\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "## sagemaker api\n",
    "import sagemaker, boto3\n",
    "from sagemaker.session import s3_input\n",
    "from sagemaker.predictor import json_serializer, json_deserializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build vocabulary and tokenize datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_articles(filepath):\n",
    "    with open(filepath) as f:\n",
    "        for line in f:\n",
    "            yield map(str.split, line.strip().split('\\t'))\n",
    "\n",
    "\n",
    "def split_sents(article):\n",
    "    return [sent.split(' ') for sent in article.split('\\t')]\n",
    "\n",
    "\n",
    "def build_vocab(sents):\n",
    "    print('Build start...')\n",
    "    tok = Tokenizer(oov_token='<UNK>', filters='')\n",
    "    tok.fit_on_texts(sents)\n",
    "    print('Build end...')\n",
    "    return tok\n",
    "\n",
    "\n",
    "def generate_positive_pairs_from_single_article(sents, tokenizer):\n",
    "    sents = list(sents)\n",
    "    idx = random.randrange(0, len(sents))\n",
    "    center = sents.pop(idx)\n",
    "    wrapper_tokens = tokenizer.texts_to_sequences(sents)\n",
    "    sent_tokens = tokenizer.texts_to_sequences([center])\n",
    "    wrapper_tokens = list(chain(*wrapper_tokens))\n",
    "    sent_tokens = list(chain(*sent_tokens))\n",
    "    yield {'in0': sent_tokens, 'in1': wrapper_tokens, 'label': 1}\n",
    "\n",
    "\n",
    "def generate_positive_pairs_from_single_file(sents_per_article, tokenizer):\n",
    "    iter_list = [generate_positive_pairs_from_single_article(sents, tokenizer)\n",
    "                 for sents in sents_per_article\n",
    "                 ]\n",
    "    return chain.from_iterable(iter_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(datadir, 'ja.wikipedia_250k.txt')\n",
    "sents_per_article =  load_articles(filepath)\n",
    "sents = chain(*sents_per_article)\n",
    "tokenizer = build_vocab(sents)\n",
    "\n",
    "# save\n",
    "datadir = '.'\n",
    "train_prefix = 'train250k'\n",
    "fname = \"wikipedia_{}.txt\".format(train_prefix)\n",
    "outfname = os.path.join(datadir, '{}_tokenized.jsonl'.format(train_prefix))\n",
    "with open(outfname, 'w') as f:\n",
    "    sents_per_article =  load_articles(filepath)\n",
    "    for sample in generate_positive_pairs_from_single_file(sents_per_article, tokenizer):\n",
    "        f.write('{}\\n'.format(json.dumps(sample)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle training data\n",
    "!shuf {outfname} > {train_prefix}_tokenized_shuf.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload preprocessed data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA=\"train250k_tokenized_shuf.jsonl\"\n",
    "\n",
    "# NOTE: define your s3 bucket and key here\n",
    "S3_BUCKET = 'YOUR_BUCKET'\n",
    "S3_KEY = 'object2vec-doc2vec'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$TRAIN_DATA\" \"$S3_BUCKET\" \"$S3_KEY\"\n",
    "\n",
    "aws s3 cp \"$1\" s3://$2/$3/input/train/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Sagemaker session, Object2Vec image, S3 input and output paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "print(\"Your notebook is running on region '{}'\".format(region))\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    " \n",
    "role = get_execution_role()\n",
    "print(\"Your IAM role: '{}'\".format(role))\n",
    "\n",
    "container = get_image_uri(region, 'object2vec')\n",
    "print(\"The image uri used is '{}'\".format(container))\n",
    "\n",
    "print(\"Using s3 buceket: {} and key prefix: {}\".format(S3_BUCKET, S3_KEY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define input channels\n",
    "\n",
    "s3_input_path = os.path.join('s3://', S3_BUCKET, S3_KEY, 'input')\n",
    "\n",
    "s3_train = s3_input(os.path.join(s3_input_path, 'train', TRAIN_DATA), \n",
    "                    distribution='ShardedByS3Key', content_type='application/jsonlines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define output path\n",
    "output_path = os.path.join('s3://', S3_BUCKET, S3_KEY, 'models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and deploy doc2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We combine four new features into our training of Object2Vec:\n",
    "\n",
    "- Negative sampling: With the new `negative_sampling_rate` hyperparameter, users of Object2Vec only need to provide positively labeled data pairs, and the algorithm automatically samples for negative data internally during training.\n",
    "\n",
    "- Weight-sharing of embedding layer: The new `tied_token_embedding_weight` hyperparameter gives user the flexibility to share the embedding weights for both encoders, and it improves the performance of the algorithm in this use-case\n",
    "\n",
    "- The new `comparator_list` hyperparameter gives users the flexibility to mix-and-match different operators so that they can tune the algorithm towards optimal performance for their applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training hyperparameters\n",
    "\n",
    "hyperparameters = {\n",
    "      \"_kvstore\": \"device\",\n",
    "      \"_num_gpus\": 'auto',\n",
    "      \"_num_kv_servers\": \"auto\",\n",
    "      \"bucket_width\": 0,\n",
    "      \"dropout\": 0.4,\n",
    "      \"early_stopping_patience\": 2,\n",
    "      \"early_stopping_tolerance\": 0.01,\n",
    "      \"enc0_layers\": \"auto\",\n",
    "      \"enc0_max_seq_len\": 50,\n",
    "      \"enc0_network\": \"pooled_embedding\",\n",
    "      \"enc0_pretrained_embedding_file\": \"\",\n",
    "      \"enc0_token_embedding_dim\": 300,\n",
    "      \"enc0_vocab_size\": len(tokenizer.word_index) + 1,\n",
    "      \"enc1_network\": \"enc0\",\n",
    "      \"enc_dim\": 300,\n",
    "      \"epochs\": 20,\n",
    "      \"learning_rate\": 0.01,\n",
    "      \"mini_batch_size\": 512,\n",
    "      \"mlp_activation\": \"relu\",\n",
    "      \"mlp_dim\": 512,\n",
    "      \"mlp_layers\": 2,\n",
    "      \"num_classes\": 2,\n",
    "      \"optimizer\": \"adam\",\n",
    "      \"output_layer\": \"softmax\",\n",
    "      \"weight_decay\": 0\n",
    "}\n",
    "\n",
    "\n",
    "hyperparameters['negative_sampling_rate'] = 3\n",
    "hyperparameters['tied_token_embedding_weight'] = \"true\"\n",
    "hyperparameters['comparator_list'] = \"hadamard\"\n",
    "hyperparameters['token_embedding_storage_type'] = 'row_sparse'\n",
    "\n",
    "    \n",
    "# get estimator\n",
    "doc2vec = sagemaker.estimator.Estimator(container,\n",
    "                                          role, \n",
    "                                          train_instance_count=1, \n",
    "                                          train_instance_type='ml.p2.xlarge',\n",
    "                                          output_path=output_path,\n",
    "                                          sagemaker_session=sess)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set hyperparameters\n",
    "doc2vec.set_hyperparameters(**hyperparameters)\n",
    "\n",
    "# fit estimator with data\n",
    "doc2vec.fit({'train': s3_train})\n",
    "#doc2vec.fit({'train': s3_train, 'validation':s3_valid, 'test':s3_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deploy model\n",
    "\n",
    "doc2vec_model = doc2vec.create_model(\n",
    "                        serializer=json_serializer,\n",
    "                        deserializer=json_deserializer,\n",
    "                        content_type='application/json')\n",
    "\n",
    "predictor = doc2vec_model.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = '今日 の 昼食 は うどん だっ た'\n",
    "sent_tokens = tokenizer.texts_to_sequences([sent])\n",
    "payload = {'instances': [{'in0': sent_tokens[0]}]}\n",
    "result = predictor.predict(payload)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
